#UCSC #CSE144

##### Reading 4.1

Goal of the chapter is on single layer neural networks, *nn*, where the basic idea is that of linear regression [[Linear Regression Algorithm]]

The *goal* being the predict the value of one or more continuous *target* variables given some *D*-dimensional vector x of *input* variables. 

A dataset typically comprises of N observations $X_n$ , where $n=1,...,N$ together with corresponding target values $t_n$ and the goal is predicting values of *t* for a new value of x. 

The simplest model for regression is one that involves a linear combination of the input variables: $y(x,w) = w_0 + w_1x_1 + ... + w_Dx_D$
Here the $(x_1,...,x_D)^T$. 

**Basis Functions**
Considering the linear combination of a fixed nonlinear functions of input variables
$$y(\omega,x) = \omega_0 +\sum_{j=1}^{M-1} \omega_j\phi_j(x)$$ 
Where $\phi_j(x)$ is known as the *basis function*. Denoting a max value of the index J by M-1, the total parameters of the model becomes *M*

Better put the *basis function, which transform the input features $x_1,x_2,...,x_D$ into a new set of variables, denoted by \phi$_j(x)$. These basis functions can be non linear such as polynomials, Gaussian functions, or sigmoid functions. Allowing the model to capture more complex non-linear relationships, hence the equation above. Where $\phi_j(x)$ is the transform of the input *x* by the basis function and the weight $w_j$ still determine the importance of each transformed feature. The key idea is instead of working with raw inputs, we transform these inputs utilizing the basis function to make the model more expressive.

**Basis Function Examples**
- Polynomial Basis: could be powers of input variable
	- $\phi_j(x)=x^j$
- Gaussian Basis Function:
	- $\phi_j(x) = exp(- \frac{(x-u_j)^2}{2s^2})$
- Sigmoid Basis Functions:
	- $\phi_j(x) = \sigma(\frac{x-u_j}{s}) = \frac{1}{1+exp(-\frac{x-u_j}{s})}$ 

**Feature Extraction and Deep Learning**
In traditional machine learning finding the right basis function was a form of *feature extraction*. Finding the best set of transformation that made the input features most useful for prediction. This process often required domain knowledge and a lot of trial and error. With *deep learning* this feature extraction is automated, and NN learn their own non linear transformation of the data through multiple layers of weights and activations

**Likelihood Function** 
With the *likelihood function* we assume the true relationship between input variables *x* and the target *t* has some noise (the target values aren't exactly equal to the predictions we make but off by some error $\epsilon$ )  We assume this error is random and follows a *Gaussian distribution* with mean zero and variance $\sigma^2$ meaning
$$t = y(x,\omega) + \epsilon$$Where $p(t∣x,w,σ^2)=N(t∣y(x,w),σ^2$, in simple terms, Given $x$ and our parameters $\omega$, the target $t$ will most likely be close to the predicted value $y(x,\omega)$, with some noise (uncertainty) around it

**Why**, we use the likelihood function to express how likely our observed data is, given a set of parameters. The goal of *maximum likelihood* MLE is to find the parameter values $\omega$ that make the observed data most probable, how we will fit the data

- helps us formalize how probable our observed data is given the parameters

**Sum of Squares Error and Max Likelihood**
The sums of squares error function $E_D(w)$ is the distance between the predicted values $y(x_n, \omega)$ and the actual target values $t_n$ defined as
$$E_D(\omega) = \frac{1}{2}\sum_{n=1}^{N}(t_n - y(x_n, \omega))^2$$
Minimizing this sum of squares error is equivalent to maximizing the likelihood under a Gaussian noise model. The intuition is minimizing the distance between our prediction and actual targets is the same as maximizing the likelihood of observing the target values.

Part of finding the optimal weights involves taking the derivative of the log-likelihood and setting it equal to zero. By differentiating with respect to the weights we find the critical points, the values of $\omega$ that minimize error. The book shows this solution of the maximum likelihood estimate $\omega_{ML}$
$$\omega_{ML} = (\Phi^T\Phi)^{-1}\Phi^Tt$$
Called the *normal equation*, provides a closed-form solution to the least squares problem in linear regression. 

- Maximizing likelihood is equivalent to minimizing sum of squares error
- The normal equation provides an efficient way to compute the optimal weights when we apply basis functions to our input

**Sequential Learning**
*Batch learning* involves using the entire dataset to update the model parameters at once. This is computationally expensive for large datasets as you must load all the data into memory and compute the gradient of the entire dataset simultaneously
*Sequential learning*/*online learning* updates the model parameters after each individual data point or small batch of data points. This approach is more scalable and useful in real time application

*Stochastic Gradient Decent*: 
Most common method for sequential learning, instead of calculating the gradient of the error function using the entire dataset, SGD computes the gradient for each data point. The update rule for the model weights is
$$\omega^{(r+1)} = \omega^{(r)} +η∇E_n$$
Where
- $-\omega(r+1)$ is the updated weight vector.
- η is the learning rate.
- $∇E_n$​ is the gradient of the error for data point $n$.

- SGD is useful for large datasets or realtime applications where we update the model with each new data point

**Regularized Least Squares**
In real-world datasets, we face a problem of *overfitting*, where the model becomes too complex and fits the training data perfectly, but performs poorly on new unseen data. We need to introduce *regularization* controlling the complexity of the model by penalizing large weights, which in turns encourages the model to generalize better. The regular error function is
$$E_D(\omega) + \lambda E_w(\omega)$$
Where
- $E_D(\omega)$ is the data dependent error (sum of squares)
- $E_W(\omega)$ regularization term, penalizing larger weights
- $\lambda$ is the hyperparameter controlling trade-off of fitting and keeping weights smaller.

A common form of regularization is *L2* also known as *ridge regression*
$$E_W(\omega) = \frac{1}{2}\omega_{j}^{2} = \frac{1}{2}\omega^T\omega$$
Penalizing large weight values, correcting overfitting

- helps prevent overfitting by penalizing large weight values, which controls model complexity and leads to better generalization on unseen data

**Multiple outputs**
Thus far we've predicted a single target variable but in many application we need to predict multiple target variables. Instead of a scalar $t$, we now predict a vector $y$ where
$$y(x,W) =W^T\phi(x)$$
- $W$ is the matrix where each column is the weights for one target variable
- $\phi(x)$ is the transformed input (basis function applied to the input)

The problem of predicting multiple outputs can be decoupled into *K independent regression problems*, where K is the number of outputs. The optimal weight matrix is given by
$$W_{ML} = (\Phi^t\Phi)^{-1}\Phi^TT$$
- extend linear regression to predict multiple target variable simultaneously. Each target has its own set of weights, but the same basis function can be used to model the relationships for all outputs

##### Reading 5.1
A *discriminant function* is used in classification problems assigning input vectors to possible classes. The function takes an input $x$ and produces a scalar output that tells you which class the input belongs to. *Linear discriminants* the decision surfaces that separate different classes

**Two Classes**
We can represent the discriminant function as a linear function of the input vector $x$
$$y(x) =w^Tx + \omega_0$$
- $w$ is the weight vector defining the orientation of the decision surface
- $\omega_0$ is the bias, which controls location of decision boundary

The decision rule is
- Class $C_1$ if $y(x) ≥ 0$ 
- Class $C_2$ if $y(x) < 0$

The decision boundary occurs when $y(x) =0$, which defines a hyper plane in 2d space (a line) 

The distance of a point from the decision surface shows that the bias $\omega_0$ controls the position of the decision surface
$$\frac{w^tx}{||w||} = -\frac{\omega_0}{||w||}$$*One vs Rest Classifiers*
When more than two classes $(K>2)$, the simplest approach is to build a set of $K-1$ classifiers, where each classifiers distinguishes one class form all the others
*One vs One Classifier*
You can build a $K(K-1)/2$ classifiers, each which separates one class from another, but can lead to ambiguity.
*K-Class Discriminants*
To avoid the ambiguities you can use a single function for all $K$ classes, for each class $C_k$, we have a linear distribution 
$$y_k(x) = w_k^Tx +\omega_{k0}$$
**One of K Coding**
for multi class programs we use *one of k coding* which means for K classes, we represent the target variable $t$ as a vector of length $K$. Thus the element corresponding to the correct class is 1, else 0

Convenient because we can interpret the values of $t_k$ as the probability that the point belongs to class $C_k$

**Least Squares For Classification**
While linear regression minimizes sum of squares error for predicting real values, we can try to apply a similar idea to classification problems. We treat target variables as binary and aim to find a set of weights that minimize error between the predicted values and target values.

**Limitations of Least Squares For Classification**
Least squares gives a closed-form solution, it may not be ideal for a classification as outliers can heavily influence the decision boundary, as sum of squares would give too much weight to points far form the boundary. And the predictions are not constrained to be in the range of $[0,1]$ so they cannot be interpreted as probabilities.

In practice use logistic regression for classification which is more robust to outliers and naturally produces outputs that can be interpreted as probabilities.

##### Readings 5.2.1 - 5.2.5

**Misclassification Rate**
The goal with classifying, is to also minimize misclassifications, for any input $x$ the classifier assigns to a specific class. A mistake happens when $x$ is assigned to the wrong class. These regions where classifiers assign points a class are called decision regions $(R_k)$

*Two Class Example*
Where we have two classes the probability of making a mistake is expressed as:
$$p(mistake) = p(x ∈ R_1, C_2) + p( x ∈ R_2,C_1) $$To minimize misclassification we assign each input vector to the class with the highest *posterior probability* $p(C_j|x)$. So for any input $x$ we assign it to class $C_k$ if $p(C_k|x) > p(C_j|x)$ for all $j \neq k$


**Expected loss**
In real-world applications minimizing misclassification may not be enough as some misclassifications can have different costs or consequences. (Book example, medical diagnoses of cancer)

The goal is to minimize expected loss, which is the average loss computed over all possible outcomes. The expected loss is given by
$$E[L] = \sum_K\sum_j\int_{R_{j}}L_{kj}[(x,C_k)dx$$
To minimize the expected loss we assign $x$ to the class $j$ that minimizes $\sum_k L_{kj}p(C_k|x)$ meaning we assign each point to the class that has the lowest weighted expected loss 

**The Reject Option**
In some cases, classification errors are particularly likely in regions of the input space where the posterior probabilities are close to each other. To deal with this uncertainty we can introduce a *reject option*. meaning that if the largest posterior probability is less than a certain threshold $\theta$, we choose not to classify $x$ and instead reject it for further analysis

Useful in application where its important to minimize high cost errors

**Inference and Decision**
- Generative Approach
	- In this approach we model *class-conditional densities* for each class and the class priors. We use Bayes Theorem to compute the posterior probabilities:
	- Once we have these probabilities, we use them to make decisions such as classifying the input based on the largest posterior probability
	- The **generative approach** is the most complex, as it requires estimating both the class-conditional densities and the class priors. However, it also provides the most flexibility, allowing us to generate synthetic data points or detect outliers
- Discriminative Approach
	- Instead of modeling the class-conditional densities, we directly model the posterior probabilities. This approach avoids having to model the joint distribution which can be complex in high dimensional spaces
	- The **discriminative approach** is simpler and often preferred when we are only interested in classification and don’t need to generate data or model the full joint distribution.
- Direct Decision Function
	- The simplest approach is to learn a discriminant function that directly maps inputs to class labels, without explicitly modeling probabilities. This approach is often used in methods like linear classifiers or neural networks where the goal is directly to assign each input
	- The **direct decision function** is the simplest but lacks probabilistic interpretation.

**Classifier Accuracy**
The performance of classifier is most commonly measured by its accuracy which the fraction of test samples that are correctly classified. We can classify these correctly and incorrectly classified predictions with True positives, True Negatives, False Positives, and False Negatives
- *True Positive (TP)*: The classifier correctly identifies a positive instance (e.g., detecting cancer when the person has cancer).
- *False Positive (FP)*: The classifier incorrectly identifies a positive instance (e.g., detecting cancer when the person does not have cancer).
- *True Negative (TN)*: The classifier correctly identifies a negative instance (e.g., detecting no cancer when the person does not have cancer).
- *False Negative (FN)*: The classifier incorrectly identifies a negative instance (e.g., detecting no cancer when the person does have cancer).

Accuracy of the classifier is the ratio of correct classifications to the total number of classifications
$$Accuracy = \frac{N_{TP}+N_{TN}}{N_{TP}+N_{FP}+N_{TN}+N_{FN}}$$
Other quantities that can be defined in terms of these are most commonly:
- Precision = $\frac{N_{TP}}{N_{TP}+N_{FP}}$, telling us how reliable a positive prediction is
- Recall = $\frac{N_{TP}}{N_{TP} + N_{FN}}$, tells us how well the classifier is able to detect actual positive cases
- False Positive Rate = $\frac{N_{FP}}{N_{F{}+N_{TN}}}$ measures how often the classifier incorrectly predicts positive
- False Discovery Rate = $\frac{N_{FP}}{N_{FP} + N_{TP}}$ inverse of precision, giving the proportion of incorrect positive predictions out of all positive predictions

**Readings 5.4.1 - 5.4.4**
In linear regression the output of the model is continuous and can take on any value between $-\infty$ and $\infty$. In classification problems we want to predict discrete class labels or posterior probabilities, values between 0 and 1. We can introduce a nonlinear transformation of the linear function, called an activation function $f(⋅)$
$$y(x,w) = f(w^Tx+\omega_0
)$$
The activation function allows us to transform the output so that it becomes appropriate for the classification. This transformation results in a *generalized linear model* (GLM).

**Fixed Basis Function**
We want to transform the input space $x$ using basis functions $\phi(x)$ which can be non linear. The basis function serves to map the original inputs into a new space where the problem becomes *linearly separable*

More sophisticated models like neural networks allow the basis functions to adapt to the data

**Logistic Regression**

Logistic regression is a two classification method where the output is modeled as the logistic sigmoid of a linear function of the input
$$p(C_1|\phi) = \sigma(w^T\phi)$$
Where $\sigma(⋅)$ is the logistic sigmoid function
$$\sigma(a) = \frac{1}{1+e^{-a}}$$
For two classes the probability of class $C_2$ is simply: $p(C_2|\phi) = 1-p(C_1|\phi)$ 

To determine the parameters $w$ of the regression model we use *maximum likelihood estimation* (MLE). Taking the negative log of the likelihood gives the *cross-entropy error*
$$E(w) = -\sum_{n=1}^{N}[t_nln(y_n) +(1-t_n)ln(1-y_n)]$$
The gradient of this error function with respect to $w$ is
$$∇E(w)=\sum_{n=1}^{N}(y_n-t_n)\phi_n$$

**Multi-class Logistic Regression**

For multi-class classification, you can generalize the logistic regression using the SoftMax function. This function converts the outputs into a set of K probabilities, one for each class
$$p(C_k|\phi) = \frac{e^{a_k}}{\sum_{j=1}^{K}e^{a_j}}$$
Where $a_k=w_k^T\phi$ is the linear function for class $C_k$

The softmax also ensures that the probabilities sum to 1 across all classes. The class with the highest probability is chose as the predicted class.
